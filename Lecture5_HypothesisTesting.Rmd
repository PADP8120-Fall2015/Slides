---
title: "Lecture 5: Hypothesis Testing"
author: "Tyler Scott"
date: "2015-07-23 ![Creative Commons License](images/cc-by.png)" 
output: ioslides_presentation
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
---

# Overview
 
## Today's Material

- Statistical inference
- Hypothesis testing
- Sample size and estimation

## Today's Goals

#Statistical inference

## Statistical inference defined

Statistical inference is the process of drawing formal conclusions from
data. 

In our class, we wil define formal statistical inference as settings where one wants to infer facts about a population using noisy
statistical data where uncertainty must be accounted for.


## Motivating example I: who's going to win the election?

In every major election, pollsters would like to know, ahead of the
actual election, who's going to win. Here, the target of
estimation (the estimand) is clear, the percentage of people in 
a particular group (city, state, county, country or other electoral
grouping) who will vote for each candidate.

We can not poll everyone. Even if we could, some polled 
may change their vote by the time the election occurs.
How do we collect a reasonable subset of data and quantify the
uncertainty in the process to produce a good guess at who will win?


## Motivating example II: is hormone replacement therapy effective? 

A large clinical trial (the Womenâ€™s Health Initiative) published results in 2002 that contradicted prior evidence on the efficacy of hormone replacement therapy for post menopausal women and suggested a negative impact of HRT for several key health outcomes. **Based on a statistically based protocol, the study was stopped early due an excess number of negative events.**

Two inferential problems. 
1. Is HRT effective?
2. How long should we continue the trial in the presence of contrary
evidence?

## What are some concerns we might have?

## Major concerns

- Is the sample representative?
- Are there known and observed, known and unobserved or unknown and unobserved variables that contaminate our conclusions?
- Is there systematic bias created by missing data or the design or conduct of the study?
- What randomness exists (explicitly or implicitly) in the data and how do we use or adjust for it?

Statistical inference requires navigating the set of assumptions and
tools and subsequently thinking about how to draw conclusions from data.


## A word about bias

-The word 'bias' is thrown around quite a bit (particularly in politics)

-In statistics, it has a fairly simple meaning: If you are estimating a parameter, and you know that you are more likely to "miss" the true value on one side versus the other, then your estimator is **biased**

-In other words, a biased estimator is likely to overstate or understate the "truth"

-Examples of **statistical bias**

## Example goals of inference

1. Estimate and quantify the uncertainty of an estimate of 
a population quantity (the proportion of people who will
  vote for a candidate).
2. Determine whether a population quantity 
  is a benchmark value ("is the treatment effective?").
3. Infer a mechanistic relationship when quantities are measured with
  noise ("What is the slope for Hooke's law?")
4. Determine the impact of a policy? ("If we reduce polution levels,
  will asthma rates decline?")

## Example tools of the trade 

1. Randomization: concerned with balancing unobserved variables that may confound inferences of interest
2. Random sampling: concerned with obtaining data that is representative 
of the population of interest
3. Hypothesis testing: concerned with decision making in the presence of uncertainty
4. Confidence intervals: concerned with quantifying uncertainty in 
estimation
5. Study design: the process of designing an experiment to minimize biases and variability

## Statistical inference = learning from data

-We use statistical inference to learn from incomplete or imperfect data. 

-What are some examples? Why? 

## Two general frames for inference

1. Sampling model: learn about population using a subset
2. Measurement error model: learn about pattern in data that are measured with error

-Often we use some element of both frames

-For instance, if we are predicting students' grades from pre-tests and characteristics:

-sampling model: use sample to learn about broader student population

-measurement model: How well do grades track with ability? How much does a given factor influence grades? 


# Hypothesis testing

##
* Hypothesis testing is concerned with making decisions using data
* A null hypothesis is specified that represents the status quo,
  usually labeled $H_0$
* The null hypothesis is assumed true and statistical evidence is required
  to reject it in favor of a research or alternative hypothesis 

## Example
* A respiratory disturbance index of more than $30$ events / hour, say, is 
  considered evidence of severe sleep disordered breathing (SDB).
* Suppose that in a sample of $100$ overweight subjects with other
  risk factors for sleep disordered breathing at a sleep clinic, the
  mean RDI was $32$ events / hour with a standard deviation of $10$ events / hour.
* We might want to test the hypothesis that 
  * $H_0 : \mu = 30$
  * $H_a : \mu > 30$
  * where $\mu$ is the population mean RDI.

## Hypothesis testing
* The alternative hypotheses are typically of the form $<$, $>$ or $\neq$
* Note that there are four possible outcomes of our statistical decision process

Truth | Decide | Result |
---|---|---|
$H_0$ | $H_0$ | Correctly accept null |
$H_0$ | $H_a$ | Type I error |
$H_a$ | $H_a$ | Correctly reject null |
$H_a$ | $H_0$ | Type II error |

## Discussion
* Consider a court of law; the null hypothesis is that the
  defendant is innocent
* We require evidence to reject the null hypothesis (convict)
* If we require little evidence, then we would increase the
  percentage of innocent people convicted (type I errors); however we
  would also increase the percentage of guilty people convicted
  (correctly rejecting the null)
* If we require a lot of evidence, then we increase the the
  percentage of innocent people let free (correctly accepting the
  null) while we would also increase the percentage of guilty people
  let free (type II errors)

## Example
* Consider our example again
* A reasonable strategy would reject the null hypothesis if
  $\bar X$ was larger than some constant, say $C$
* Typically, $C$ is chosen so that the probability of a Type I
  error, $\alpha$, is $.05$ (or some other relevant constant)
* $\alpha$ = Type I error rate = Probability of rejecting the null hypothesis when, in fact, the null hypothesis is correct

## Example continued

$$
\begin{align}
0.05  & =  P\left(\bar X \geq C ~|~ \mu = 30 \right) \\
      & =  P\left(\frac{\bar X - 30}{10 / \sqrt{100}} \geq \frac{C - 30}{10/\sqrt{100}} ~|~ \mu = 30\right) \\
      & =  P\left(Z \geq \frac{C - 30}{1}\right) \\
\end{align}
$$

* Hence $(C - 30) / 1 = 1.645$ implying $C = 31.645$
* Since our mean is $32$ we reject the null hypothesis


## Discussion
* In general we don't convert $C$ back to the original scale
* We would just reject because the Z-score; which is how many
  standard errors the sample mean is above the hypothesized mean
  $$
  \frac{32 - 30}{10 / \sqrt{100}} = 2
  $$
  is greater than $1.645$
* Or, whenever $\sqrt{n} (\bar X - \mu_0) / s > Z_{1-\alpha}$


## General rules
* The $Z$ test for $H_0:\mu = \mu_0$ versus 
  * $H_1: \mu < \mu_0$
  * $H_2: \mu \neq \mu_0$
  * $H_3: \mu > \mu_0$ 
* Test statistic $ TS = \frac{\bar{X} - \mu_0}{S / \sqrt{n}} $
* Reject the null hypothesis when 
  * $TS \leq -Z_{1 - \alpha}$
  * $|TS| \geq Z_{1 - \alpha / 2}$
  * $TS \geq Z_{1 - \alpha}$


## Notes
* We have fixed $\alpha$ to be low, so if we reject $H_0$ (either
  our model is wrong) or there is a low probability that we have made
  an error
* We have not fixed the probability of a type II error, $\beta$;
  therefore we tend to say ``Fail to reject $H_0$'' rather than
  accepting $H_0$
* Statistical significance is not the same as scientific (or substantive) significance
* The region of TS values for which you reject $H_0$ is called the
  rejection region

## More notes
* The $Z$ test requires the assumptions of the CLT and for $n$ to be large enough
  for it to apply
* If $n$ is small, then a Gossett's $T$ test is performed exactly in the same way,
  with the normal quantiles replaced by the appropriate Student's $T$ quantiles and
  $n-1$ df
* The probability of rejecting the null hypothesis when it is false is called *power*
* Power is a used a lot to calculate sample sizes for experiments

## Example reconsidered
- Consider our example again. Suppose that $n= 16$ (rather than
$100$). Then consider that
$$
.05 = P\left(\frac{\bar X - 30}{s / \sqrt{16}} \geq t_{1-\alpha, 15} ~|~ \mu = 30 \right)
$$
- So that our test statistic is now $\sqrt{16}(32 - 30) / 10 = 0.8 $, while the critical value is $t_{1-\alpha, 15} = 1.75$. 
- We now fail to reject.

## Two sided tests
* Suppose that we would reject the null hypothesis if in fact the 
  mean was too large or too small
* That is, we want to test the alternative $H_a : \mu \neq 30$
  (doesn't make a lot of sense in our setting)
* Then note
$$
 \alpha = P\left(\left. \left|\frac{\bar X - 30}{s /\sqrt{16}}\right| > t_{1-\alpha/2,15} ~\right|~ \mu = 30\right)
$$
* That is we will reject if the test statistic, $0.8$, is either
  too large or too small, but the critical value is calculated using
  $\alpha / 2$
* In our example the critical value is $2.13$, so we fail to reject.

## Connections with confidence intervals (next week...)

* Consider testing $H_0: \mu = \mu_0$ versus $H_a: \mu \neq \mu_0$
* Take the set of all possible values for which you fail to reject $H_0$, this set is a $(1-\alpha)100\%$ confidence interval for $\mu$
* The same works in reverse; if a $(1-\alpha)100\%$ interval
  contains $\mu_0$, then we *fail  to* reject $H_0$

# Sample size

## Numerical limits

- Imagine a sequence

  - $a_1 = .9$,
  - $a_2 = .99$,
  - $a_3 = .999$, ...

- Clearly this sequence converges to $1$
- Definition of a limit: For any fixed distance we can find a point in the sequence so that the sequence is closer to the limit than that distance from that point on


## Limits of random variables

- The problem is harder for random variables
- Consider $\bar X_n$ the sample average of the first $n$ of a collection of $iid$ observations

  - Example $\bar X_n$ could be the average of the result of $n$ coin flips (i.e. the sample proportion of heads)

- We say that $\bar X_n$ converges in probability to a limit if for any fixed distance the  probability of $\bar X_n$ being closer (further away) than that distance from the limit converges to one (zero)


## The Law of Large Numbers

- Establishing that a random sequence converges to a limit is hard
- Fortunately, we have a theorem that does all the work for us, called
    the **Law of Large Numbers**
- The law of large numbers states that if $X_1,\ldots X_n$ are iid from a population with mean $\mu$ and variance $\sigma^2$ then $\bar X_n$ converges in probability to $\mu$
- (There are many variations on the LLN; we are using a lazy version, the best kind of version)

## Law of large numbers in action
```{r, fig.height=3.75, fig.width=5.5}
n <- 10000; means <- cumsum(rnorm(n)) / (1  : n)
plot(1 : n, means, type = "l", lwd = 2, frame = FALSE, 
     ylab = "cumulative means", xlab = "sample size")
abline(h = 0)
```


## Discussion
- An estimator is **consistent** if it converges to what you want to estimate
  - Consistency is neither necessary nor sufficient for one estimator to be better than another
  - Typically, good estimators are consistent; it's not too much to ask that if we go to the trouble of collecting an infinite amount of data that we get the right answer
  
##

- The LLN basically states that the sample mean is consistent
- The sample variance and the sample standard deviation are consistent as well
- Recall also that the sample mean and the sample variance are unbiased as well
- (The sample standard deviation is biased, by the way)

## The Central Limit Theorem

- The **Central Limit Theorem** (CLT) is one of the most important theorems in statistics
- For our purposes, the CLT states that the distribution of averages of iid variables, properly normalized, becomes that of a standard normal as the sample size increases
- The CLT applies in an endless variety of settings

## CLT formalized

- Let $X_1,\ldots,X_n$ be a collection of iid random variables with mean $\mu$ and variance $\sigma^2$
- Let $\bar X_n$ be their sample average
- Then $\frac{\bar X_n - \mu}{\sigma / \sqrt{n}}$ has a distribution like that of a standard normal for large $n$.
- Remember the form
$$\frac{\bar X_n - \mu}{\sigma / \sqrt{n}} = 
    \frac{\mbox{Estimate} - \mbox{Mean of estimate}}{\mbox{Std. Err. of estimate}}.
$$
- Usually, replacing the standard error by its estimated value doesn't change the CLT


## Example

- Simulate a standard normal random variable by rolling $n$ (six sided)
- Let $X_i$ be the outcome for die $i$
- Then note that $\mu = E[X_i] = 3.5$
- $Var(X_i) = 2.92$ 
- SE $\sqrt{2.92 / n} = 1.71 / \sqrt{n}$
- Standardized mean
$$
    \frac{\bar X_n - 3.5}{1.71/\sqrt{n}}
$$ 

## Simulation of mean of $n$ dice
```{r, echo = FALSE, fig.width=9, fig.height = 3}
par(mfrow = c(1, 3))
for (n in c(1, 2, 6)){
  temp <- matrix(sample(1 : 6, n * 10000, replace = TRUE), ncol = n)
  temp <- apply(temp, 1, mean)
  temp <- (temp - 3.5) / (1.71 / sqrt(n)) 
  dty <- density(temp)
  plot(dty$x, dty$y, xlab = "", ylab = "density", type = "n", xlim = c(-3, 3), ylim = c(0, .5))
  title(paste("sample mean of", n, "obs"))
  lines(seq(-3, 3, length = 100), dnorm(seq(-3, 3, length = 100)), col = grey(.8), lwd = 3)
  lines(dty$x, dty$y, lwd = 2)
}
```


## Coin CLT

 - Let $X_i$ be the $0$ or $1$ result of the $i^{th}$ flip of a possibly unfair coin
- The sample proportion, say $\hat p$, is the average of the coin flips
- $E[X_i] = p$ and $Var(X_i) = p(1-p)$
- Standard error of the mean is $\sqrt{p(1-p)/n}$
- Then
$$
    \frac{\hat p - p}{\sqrt{p(1-p)/n}}
$$
will be approximately normally distributed

## 50/50 coin flips...

```{r, echo = FALSE, fig.width=7.5, fig.height = 3.5}
par(mfrow = c(1, 3))
for (n in c(1, 10, 20)){
  temp <- matrix(sample(0 : 1, n * 10000, replace = TRUE), ncol = n)
  temp <- apply(temp, 1, mean)
  temp <- (temp - .5) * 2 * sqrt(n)
  dty <- density(temp)
  plot(dty$x, dty$y, xlab = "", ylab = "density", type = "n", xlim = c(-3, 3), ylim = c(0, .5))
  title(paste("sample mean of", n, "obs"))
  lines(seq(-3, 3, length = 100), dnorm(seq(-3, 3, length = 100)), col = grey(.8), lwd = 3)
  lines(dty$x, dty$y, lwd = 2)
}

```


## CLT in practice

- In practice the CLT is mostly useful as an approximation
$$
    P\left( \frac{\bar X_n - \mu}{\sigma / \sqrt{n}} \leq z \right) \approx \Phi(z).  
$$
- Recall $1.96$ is a good approximation to the $.975^{th}$ quantile of the standard normal
- Consider
$$
    \begin{eqnarray*}
      .95 & \approx & P\left( -1.96 \leq \frac{\bar X_n - \mu}{\sigma / \sqrt{n}} \leq 1.96 \right)\\ \\
      & =       & P\left(\bar X_n +1.96 \sigma/\sqrt{n} \geq \mu \geq \bar X_n - 1.96\sigma/\sqrt{n} \right),\\
    \end{eqnarray*}
$$


# Goal check

